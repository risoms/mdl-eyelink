{"cells":[{"cell_type":"markdown","source":[" <h5>Example setup for Eyelink 1000 Plus, using PsychoPy 3.0.</h5>"],"metadata":{}},{"cell_type":"markdown","source":[" Created on Wed Feb 13 15:37:43 2019\\s\\s\\s\n"," @author: Semeon Risom\\s\\s\\s\n"," @email: semeon.risom@gmail.com\\s\\s\\s\n"," Sample code to run SR Research Eyelink eyetracking system. Code is optimized for the Eyelink 1000\\s\\s\\s\n"," Plus (5.0), but should be compatiable with earlier systems.\\s\\s\\s"],"metadata":{}},{"cell_type":"markdown","source":[" <ul class=\"list-container\">\n","     <li>\n","         <div class=\"title\">The sequence of operations for implementing the trial is:</div>\n","         <ol class=\"list\">\n","             <li>[Import the mdl package](example.ipynb#import).</li>\n","             <li>Initialize the `mdl.eyetracking()` package.</li>\n","             <li>Connect to the Eyelink Host.</li>\n","             <li>Set the dominamt eye.</li>\n","             <li>Start calibration.</li>\n","             <li>Start recording.</li>\n","             <li>Stop recording.</li>\n","             <li>Finish recording.</li>\n","         </ol>\n","     </li>\n","     <li>\n","         <div class=\"title\">Optional commands include:</div>\n","         <ol>\n","             <li>Drift correction.</li>\n","             <li>Initiate gaze contigent event.</li>\n","             <li>Collect real-time gaze coordinates from Eyelink.</li>\n","             <li>Send messages to Eyelink.</li>\n","         </ol>\n","     </li>\n"," </ul>"],"metadata":{}},{"cell_type":"markdown","source":[" <h5>Import packages.</h5><br>"],"metadata":{}},{"source":["import os\n","import sys\n","from psychopy import visual\n","import mdl"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Initialize the mdl.eyetracking() package.</h5><br>\n"," Before initializing, make sure code is placed after PsychoPy window instance has been created in the experiment file.\n"," This window will be used in the calibration function."],"metadata":{}},{"source":["# Creating `psychopy.visual.window.Window` instance (for demonstration purposes only)\n","subject = 1\n","screensize = [1920, 1080]\n","window = visual.Window(size=screensize, fullscr=False, allowGUI=True, units='pix', \n","                       winType='pyglet', color=[110,110,110], colorSpace='rgb255')"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#start package\n","eyetracking = mdl.eyetracking(libraries=False, window=window, subject=subject)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Connect to the Eyelink Host.</h5><br>\n"," This controls the parameters to be used when running the eyetracker."],"metadata":{}},{"source":["param = eyetracking.connect(calibration_type=13)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Set the dominamt eye.</h5><br>\n"," This step is required for recieving gaze coordinates from Eyelink->PsychoPy."],"metadata":{}},{"source":["dominant_eye = 'left'\n","eye_used = eyetracking.set_eye_used(eye=dominant_eye)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Start calibration.</h5><br>\n"," If using PsychoPy, be sure to place [eyetracking.calibration()](eyetracking.rst#mdl.eyetracking.eyetracking.calibration)\n"," after the `psychopy.visual.window.Window` instance. The instance will be used as a parameter in the function."],"metadata":{}},{"source":["eyetracking.calibration()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Enter the key \"o\" on the calibration instance. This will begin the task. \n","# The Calibration, Validation, 'task-start' events are controlled by the keyboard.\n","# Calibration (\"c\"), Validation (\"v\"), task-start (\"o\") respectively."],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>(Optional) Print message to console/terminal.</h5><br>\n"," Allows printing color coded messages to console/terminal/cmd. This may be useful for debugging issues."],"metadata":{}},{"source":["eyetracking.console(c=\"blue\", msg=\"eyetracking.calibration() started\")"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>(Optional) Drift correction.</h5><br>\n"," This can be done at any point after calibration, including before and after\n"," [eyetracking.start_recording()](eyetracking.rst#mdl.eyetracking.eyetracking.start_recording) has started."],"metadata":{}},{"source":["eyetracking.drift_correction()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Start recording.</h5><br>\n"," Note: This should be run at the start of the trial. Also, there is an intentional delay of 150 msec to\n"," allow the Eyelink to buffer gaze samples that will show up in your data."],"metadata":{}},{"source":["# Create stimulus (demonstration purposes only).\n","filename = \"8380.bmp\" #filename\n","path = os.getcwd() + \"/data/stimulus/\" + filename #file path\n","size = (1024, 768) #image size\n","pos = (screensize[0]/2, screensize[1]/2) #positioning image at center of screen\n","stimulus = visual.ImageStim(win=window, image=path, size=size, pos=(0,0), units='pix')\n","\n","#start\n","eyetracking.start_recording(trial=1, block=1)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>(Optional) Initiate gaze contigent event.</h5><br>\n"," This is used for realtime data collection from Eyelink->PsychoPy."],"metadata":{}},{"source":["# In the example, a participant is qto look at the bounding cross for a duration\n","# of 2000 msec before continuing the task. If this doesn't happen and a maxinum maxinum duration of \n","# 10000 msec has occured first drift correction will start.\n","bound = dict(left=860, top=440, right=1060, bottom=640)\n","t_min = 2000\n","t_max = 10000\n","\n","# start\n","eyetracking.gc(bound=bound, t_min=t_min, t_max=t_max)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>(Optional) Collect real-time gaze coordinates from Eyelink.</h5><br>\n"," Note: This command should be repeated at an interval of 1000/(Eyelink pacing interval) msec to prevent oversampling."],"metadata":{}},{"source":["# In our example, the sampling rate of our device (Eyelink 1000 Plus) is 500Hz.\n","s1 = 0 # set current time to 0\n","lgxy = [] # create list of gaze coordinates (demonstration purposes only)\n","s0 = time.clock() # initial timestamp\n","# repeat\n","while True:\n","    # if difference between starting and current time is greater than > 2.01 msec, collect new sample\n","    diff = (s1 - s0)\n","    if diff >= .00201:\n","        print(s1)\n","        gxy, ps, s = eyetracking.sample(eye_used=eye_used) # get gaze coordinates, pupil size, and sample\n","        lgxy.append(gxy) # store in list (not required; demonstration purposes only)\n","        s0 = time.clock() # update starting time\n","    #else set current time\n","    else: \n","        s1 = time.clock()\n","\n","    #break `while` statement if list of gaze coordiantes >= 20 (not required; demonstration purposes only)\n","    if len(lgxy) >= 200: break"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>(Optional) Send messages to Eyelink.</h5><br>\n"," This allows post-hoc processing of event markers (i.e. \"stimulus onset\")."],"metadata":{}},{"source":["# Sending message \"stimulus onset\".\n","msg = \"stimulus onset\"\n","eyetracking.send_message(msg=msg)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Stop recording.</h5><br>\n"," Also (optional) provides trial-level variables to Eyelink.\n"," Note: Variables sent are optional. If they being included, they must be in `python dict` format."],"metadata":{}},{"source":["# set variables\n","variables = dict(stimulus=filename, trial_type='encoding', race=\"black\")\n","# stop recording\n","eyetracking.stop_recording(trial=1, block=1, variables=variables)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Finish recording.</h5><br>"],"metadata":{}},{"source":["eyetracking.finish_recording()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}
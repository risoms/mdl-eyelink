{"cells":[{"source":["# Created on Wed Feb 13 15:37:43 2019\n","# @author: Semeon Risom\n","# @email: semeon.risom@gmail.com.\n","# Sample code to run SR Research Eyelink eyetracking system. Code is optimized for the Eyelink 1000 \n","# Plus (5.0), but should be compatiable with earlier systems."],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# To Do:\n","# Finish eyetracking.drift_correction()\n","# Finish eyetracking.roi()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# import\n","from psychopy import visual, core\n","import mdl"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Initialize the Eyelink.\n","# Before initializing, ensure psychopy window instance has been created in the experiment file. \n","# This window will be used in the calibration function.\n","#\n","# ```psychopy.visual.window.Window``` instance (for demonstration purposes only)\n","window = visual.Window(size=[1920, 1080], fullscr=False, screen=0, allowGUI=True, units='pix',\n","                       monitor='Monitor', winType='pyglet', color=[110,110,110], colorSpace='rgb255')\n","subject = 1\n","eyetracking = mdl.eyetracking(libraries=False, window=window, subject=subject)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Setting the dominant eye. This step is especially critical for transmitting gaze coordinates from Eyelink->Psychopy.\n","#\n","dominant_eye = 'left'\n","eye_used = eyetracking.set_eye_used(eye=dominant_eye)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Start calibration.\n","# Before running the calibration, ensure psychopy window instance has been created in the experiment file. \n","# This window will be used in the calibration function.\n","#\n","# ```psychopy.visual.window.Window``` instance (for demonstration purposes only)\n","# start\n","eyetracking.calibration()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Enter the key \"o\" on the ```psychopy.visual.window.Window``` instance. This will begin the task. \n","# The Calibration, Validation, 'task-start' events are controlled by the keyboard.\n","# Calibration (\"c\"), Validation (\"v\"), task-start (\"o\") respectively."],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# (Optional) Print message to console/terminal. This may be useful for debugging issues.\n","eyetracking.console(c=\"green\", msg=\"eyetracking.calibration() started\")"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Drift correction. This can be done at any point after calibration, including after \n","# eyetracking.start_recording has started. #!! To do. Finish.\n","#\n","attempt = 1\n","eyetracking.drift_correction(window=window, attempt=attempt, limit=999, core=core, thisExp=None)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Region of interest. This is used for realtime data collection from eyelink->psychopy.\n","# For example, this can be used to require participant to look at the fixation cross for a duration\n","# of 500 msec before continuing the task.\n","# \n","# Using the eyetracking.roi function to collect samples with the center of the screen.\n","roi = dict(center=[860,1060,640,440])\n","# start\n","eyetracking.roi(window=window, region=roi)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Start recording. This should be run at the start of the trial. \n","# Note: There is an intentional delay of 150 msec to allow the Eyelink to buffer gaze samples.\n","eyetracking.start_recording(trial=1, block=1)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Collect current gaze coordinates from Eyelink (only if needed in experiment). This command should be \n","# looped at an interval of sample/2.01 msec to prevent oversampling (500Hz).\n","#\n","# get time\n","import time\n","s1 = 0 # set current time to 0\n","lgxy = [] # create list of gaze coordinates (demonstration purposes only)\n","s0 = time.clock() # initial timestamp\n","# repeat\n","while True:\n","    # if difference between starting and current time is greater than > 2.01 msec, collect new sample\n","    if (s1 - s0) >= .00201:\n","        gxy = eyetracking.sample(eye_used=eye_used) # get gaze coordinates\n","        lgxy.append(gxy) # store in list\n","        s0 = time.clock() # update starting time\n","    #else set current time\n","    else: \n","        s1 = time.clock()\n","\n","    #break `while` statement if list of gaze coordiantes >= 20 (demonstration purposes only)\n","    if len(lgxy) >= 20: break"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Send messages to Eyelink. This allows post-hoc processing of timing related events (i.e. \"stimulus onset\").\n","# Sending message \"stimulus onset\".\n","msg = \"stimulus onset\"\n","eyetracking.send_message(msg=msg)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Stops Eyelink recording. Also allows transmission of trial-level variables (optional) to Eyelink.\n","# Note: Variables sent are optional. If they being included, they must be in ```python dict``` format.\n","#\n","# set variables\n","variables = dict(stimulus='001B_F.jpg', trial_type='encoding', race=\"black\")\n","# stop recording\n","eyetracking.stop_recording(trial=1, block=1, variables=variables)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Finish Eyelink recording.\n","eyetracking.finish_recording()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}